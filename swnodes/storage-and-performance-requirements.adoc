---
permalink: swnodes/storage-and-performance-requirements.html 
sidebar: sidebar 
keywords: storage requirements, performance requirements, host storage, host volumes, netapp ontap, fabricpool 
summary: Sie müssen die Storage-Anforderungen für StorageGRID-Nodes verstehen, damit Sie ausreichend Speicherplatz für die Erstkonfiguration und die künftige Storage-Erweiterung bereitstellen können. 
---
= Storage- und Performance-Anforderungen erfüllt
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Sie müssen die Storage-Anforderungen für StorageGRID-Nodes verstehen, damit Sie ausreichend Speicherplatz für die Erstkonfiguration und die künftige Storage-Erweiterung bereitstellen können.

Die Speicher- und Leistungsanforderungen variieren je nach Ihrer softwarebasierten Knotenimplementierung.


NOTE: „Linux“ bezieht sich auf eine RHEL-, Ubuntu- oder Debian-Bereitstellung.  Eine Liste der unterstützten Versionen finden Sie im https://imt.netapp.com/matrix/#welcome["NetApp Interoperabilitäts-Matrix-Tool (IMT)"^] .



== Speicherkategorien

StorageGRID Nodes erfordern drei logische Storage-Kategorien:

* *Container Pool* -- Performance-Tier (10K SAS oder SSD) Speicher für die Knoten-Container, die dem Container-Engine-Speichertreiber zugewiesen wird, wenn Sie die Container-Engine auf den Hosts installieren und konfigurieren, die Ihre StorageGRID-Knoten unterstützen.
* *Systemdaten* -- Performance-Tier (10.000 SAS oder SSD) Speicher für persistenten Speicher pro Node von Systemdaten und Transaktionsprotokollen, die die StorageGRID Host Services nutzen und einzelnen Nodes zuordnen werden.
* *Objektdaten* -- Performance-Tier (10.000 SAS oder SSD) Storage und Capacity-Tier (NL-SAS/SATA) Massenspeicher für die persistente Speicherung von Objektdaten und Objekt-Metadaten.


Sie müssen RAID-gestützte Blockgeräte für alle Speicherkategorien verwenden. Nicht redundante Festplatten, SSDs oder JBODs werden nicht unterstützt. Sie können für jede der Storage-Kategorien gemeinsam genutzten oder lokalen RAID-Speicher verwenden. Wenn Sie jedoch die Funktion zur Node-Migration in StorageGRID verwenden möchten, müssen Sie sowohl System- als auch Objektdaten auf Shared Storage speichern. Weitere Informationen finden Sie unter link:node-container-migration-requirements.html["Anforderungen für die Container-Migration für Nodes"].



== Performance-Anforderungen erfüllt

Die Performance der für den Container-Pool verwendeten Volumes, Systemdaten und Objektmetadaten wirkt sich erheblich auf die Gesamt-Performance des Systems aus. Sie sollten Performance-Tier-Storage (10.000 SAS oder SSD) für diese Volumes verwenden, um eine angemessene Festplatten-Performance in Bezug auf Latenz, Input/Output Operations per Second (IOPS) und Durchsatz sicherzustellen. Sie können Capacity-Tier (NL-SAS/SATA)-Storage für den persistenten Storage von Objektdaten verwenden.

Für die Volumes, die für den Container-Pool, Systemdaten und Objektdaten verwendet werden, muss ein Write-Back-Caching aktiviert sein. Der Cache muss sich auf einem geschützten oder persistenten Medium befinden.



== Anforderungen für Hosts, die NetApp ONTAP-Speicher verwenden

Wenn der StorageGRID Node Storage verwendet, der aus einem NetApp ONTAP System zugewiesen wurde, vergewissern Sie sich, dass auf dem Volume keine FabricPool-Tiering-Richtlinie aktiviert ist. Das Deaktivieren von FabricPool Tiering für Volumes, die in Verbindung mit StorageGRID Nodes verwendet werden, vereinfacht die Fehlerbehebung und Storage-Vorgänge.


NOTE: Verwenden Sie FabricPool niemals, um StorageGRID-bezogene Daten in das Tiering zurück zu StorageGRID selbst zu verschieben. Das Tiering von StorageGRID-Daten zurück in die StorageGRID verbessert die Fehlerbehebung und reduziert die Komplexität von betrieblichen Abläufen.



== Anzahl der erforderlichen Hosts

Jeder StorageGRID Standort erfordert mindestens drei Storage-Nodes.


NOTE: Führen Sie in einer Produktionsimplementierung nicht mehr als einen Storage Node auf einem einzelnen physischen oder virtuellen Host aus. Die Verwendung eines dedizierten Hosts für jeden Speicherknoten stellt eine isolierte Ausfalldomäne zur Verfügung.

Andere Node-Typen wie Admin-Nodes oder Gateway-Nodes können auf denselben Hosts implementiert oder je nach Bedarf auf ihren eigenen dedizierten Hosts implementiert werden.


NOTE: Disk Snapshots können nicht zur Wiederherstellung von Grid Nodes verwendet werden. Lesen Sie stattdessen die link:../maintain/warnings-and-considerations-for-grid-node-recovery.html["Recovery von Grid Nodes"] Verfahren für jeden Node-Typ.



== Anzahl der Speichervolumes für jeden Knoten

In der folgenden Tabelle ist die Anzahl der für jeden Host erforderlichen Storage Volumes (LUNs) und die Mindestgröße für jede LUN angegeben, basierend darauf, welche Nodes auf diesem Host implementiert werden.

Die maximale getestete LUN-Größe beträgt 39 TB.


NOTE: Diese Nummern gelten für jeden Host, nicht für das gesamte Raster.

|===
| Zweck der LUN | Storage-Kategorie | Anzahl LUNs | Minimale Größe/LUN 


 a| 
Storage-Pool für Container-Engine
 a| 
Container-Pool
 a| 
1
 a| 
Gesamtzahl der Nodes × 100 GB



 a| 
`/var/local` Datenmenge
 a| 
Systemdaten
 a| 
1 für jeden Node auf diesem Host
 a| 
100GB



 a| 
Storage-Node
 a| 
Objektdaten
 a| 
3 für jeden Speicherknoten auf diesem Host

*Hinweis:* Ein auf Linux-Software basierender Speicherknoten kann 1 bis 48 Speichervolumes haben.  Ein auf VMware-Software basierender Speicherknoten kann 1 bis 16 Speichervolumes haben.  Es werden mindestens 3 Speichervolumes empfohlen.
 a| 
12 TB (mindestens 4 TB/LUN)

Maximale getestete LUN-Größe: 39 TB.

Sehen <<storage_req_SN,Storage-Anforderungen für Storage-Nodes>> für weitere Informationen.



 a| 
Storage-Node (nur Metadaten)
 a| 
Objekt-Metadaten
 a| 
1
 a| 
Mindestens 4 TB/LUN

Maximale getestete LUN-Größe: 39 TB.

Sehen <<storage_req_SN,Storage-Anforderungen für Storage-Nodes>> für weitere Informationen.

*Hinweis*: Nur ein Rangedb ist für Metadaten-only Storage Nodes erforderlich.



 a| 
Prüfprotokolle für Admin-Node
 a| 
Systemdaten
 a| 
1 für jeden Admin-Node auf diesem Host
 a| 
200GB



 a| 
Admin-Node-Tabellen
 a| 
Systemdaten
 a| 
1 für jeden Admin-Node auf diesem Host
 a| 
200GB

|===

NOTE: Abhängig von der konfigurierten Prüfebene, der Größe der Benutzereingaben wie dem S3-Objektschlüsselnamen und der Menge der Prüfprotokolldaten, die Sie aufbewahren müssen, müssen Sie möglicherweise die Größe der Prüfprotokoll-LUN auf jedem Admin-Knoten erhöhen.  Im Allgemeinen generiert ein Grid ungefähr 1 KB Prüfdaten pro S3-Vorgang. Dies würde bedeuten, dass ein 200 GB LUN 70 Millionen Vorgänge pro Tag oder 800 Vorgänge pro Sekunde für zwei bis drei Tage unterstützen würde.



== Minimaler Speicherplatz für einen Host

In der folgenden Tabelle ist der erforderliche Mindestspeicherplatz für jeden Node-Typ aufgeführt. Anhand dieser Tabelle können Sie bestimmen, welcher Storage-Mindestbetrag für den Host in jeder Storage-Kategorie bereitgestellt werden muss. Dabei können Sie festlegen, welche Nodes auf diesem Host implementiert werden.


NOTE: Disk Snapshots können nicht zur Wiederherstellung von Grid Nodes verwendet werden. Lesen Sie stattdessen die link:../maintain/warnings-and-considerations-for-grid-node-recovery.html["Recovery von Grid Nodes"] Verfahren für jeden Node-Typ.

Jeder Knotenhost benötigt eine 100 GB große LUN für das Betriebssystem.

|===
| Node-Typ | Container-Pool | Systemdaten | Objektdaten 


| Storage-Node  a| 
100GB
 a| 
100GB
 a| 
4.000GB



 a| 
Admin-Node
 a| 
100GB
 a| 
500 GB (3 LUNs)
 a| 
_Nicht zutreffend_



 a| 
Gateway-Node
 a| 
100GB
 a| 
100GB
 a| 
_Nicht zutreffend_

|===


== Beispiel: Berechnen des Speicherbedarfs für einen Host oder eine virtuelle Maschine

Angenommen, Sie planen, drei Knoten auf demselben Host oder derselben virtuellen Maschine bereitzustellen: einen Speicherknoten, einen Admin-Knoten und einen Gateway-Knoten.  Sie sollten dem Host mindestens neun Speichervolumes zur Verfügung stellen.  Sie benötigen mindestens 300 GB Performance-Tier-Speicher für die Knotencontainer, 700 GB Performance-Tier-Speicher für Systemdaten und Transaktionsprotokolle und 12 TB Capacity-Tier-Speicher für Objektdaten.

[role="tabbed-block"]
====
.Linux-Host-Beispiel
--
|===
| Node-Typ | Zweck der LUN | Anzahl LUNs | Die LUN-Größe 


| Storage-Node  a| 
Storage-Pool für Container-Engine
 a| 
1
 a| 
300 GB (100 GB/Node)



 a| 
Storage-Node
 a| 
`/var/local` Datenmenge
 a| 
1
 a| 
100GB



| Storage-Node  a| 
Objektdaten
 a| 
3
 a| 
12 TB (4 TB/LUN)



 a| 
Admin-Node
 a| 
`/var/local` Datenmenge
 a| 
1
 a| 
100GB



| Admin-Node  a| 
Prüfprotokolle für Admin-Node
 a| 
1
 a| 
200GB



| Admin-Node  a| 
Admin-Node-Tabellen
 a| 
1
 a| 
200GB



 a| 
Gateway-Node
 a| 
`/var/local` Datenmenge
 a| 
1
 a| 
100GB



 a| 
*Gesamt*
 a| 
 a| 
*9*
 a| 
*Container-Pool:* 300 GB

*Systemdaten:* 700 GB

*Objektdaten:* 12,000 GB

|===
--
.Beispiel einer virtuellen VMware-Maschine
--
|===
| Node-Typ | Zweck der LUN | Anzahl LUNs | Die LUN-Größe 


 a| 
Storage-Node
 a| 
Betriebssystem-Volume
 a| 
1
 a| 
100GB



| Storage-Node  a| 
Objektdaten
 a| 
3
 a| 
12 TB (4 TB/LUN)



 a| 
Admin-Node
 a| 
Betriebssystem-Volume
 a| 
1
 a| 
100GB



| Admin-Node  a| 
Prüfprotokolle für Admin-Node
 a| 
1
 a| 
200GB



| Admin-Node  a| 
Admin-Node-Tabellen
 a| 
1
 a| 
200GB



 a| 
Gateway-Node
 a| 
Betriebssystem-Volume
 a| 
1
 a| 
100GB



 a| 
*Gesamt*
 a| 
 a| 
*8*
 a| 
*Systemdaten:* 700 GB

*Objektdaten:* 12,000 GB

|===
--
====


== Spezifische Speicheranforderungen für Speicherknoten

Linux und VMware haben unterschiedliche Speicheranforderungen für Speicherknoten:

* Ein Linux-Software-basierter Speicherknoten kann 1 bis 48 Speichervolumes haben
* Ein VMware-Software-basierter Storage Node kann 1 bis 16 Speichervolumes haben
* Es werden drei oder mehr Speichervolumes empfohlen.
* Jedes Speichervolumen sollte mindestens 4 TB groß sein.



NOTE: Ein Appliance-Speicherknoten kann außerdem über bis zu 48 Speichervolumes verfügen.

Wie in der Abbildung dargestellt, reserviert StorageGRID Speicherplatz für Objekt-Metadaten auf dem Storage Volume 0 jedes Storage-Nodes. Alle verbleibenden Speicherplatz auf dem Storage-Volume 0 und anderen Storage-Volumes im Storage-Node werden ausschließlich für Objektdaten verwendet.

image::../media/metadata_space_storage_node.png[Metadaten-Speicherplatz-Storage-Node]

Um Redundanz zu gewährleisten und Objekt-Metadaten vor Verlust zu schützen, speichert StorageGRID drei Kopien der Metadaten für alle Objekte im System an jedem Standort. Die drei Kopien der Objektmetadaten werden gleichmäßig auf alle Storage-Nodes an jedem Standort verteilt.

Bei der Installation eines Grid mit metadatenreinen Storage-Nodes muss das Grid auch eine Mindestanzahl an Nodes für Objekt-Storage enthalten. Weitere Informationen zu nur Metadaten-Storage-Nodes finden Sie unterlink:../primer/what-storage-node-is.html#types-of-storage-nodes["Typen von Storage-Nodes"].

* Für ein Grid an einem Standort werden mindestens zwei Storage-Nodes für Objekte und Metadaten konfiguriert.
* Bei einem Grid mit mehreren Standorten werden mindestens ein Storage Node pro Standort für Objekte und Metadaten konfiguriert.


Wenn Sie Volume 0 eines neuen Storage-Node Speicherplatz zuweisen, müssen Sie sicherstellen, dass für den Anteil aller Objekt-Metadaten des Node ausreichend Speicherplatz vorhanden ist.

* Mindestens müssen Sie Volume 0 mindestens 4 TB zuweisen.
+

NOTE: Wenn Sie nur ein Storage-Volume für einen Storage-Node verwenden und dem Volume maximal 4 TB zuweisen, kann der Storage-Node beim Starten und Speichern von Objektmetadaten in den schreibgeschützten Storage-Status wechseln.

+

NOTE: Wenn Sie Volume 0 weniger als 500 GB zuweisen (nur für den nicht-produktiven Einsatz), sind 10 % der Kapazität des Speicher-Volumes für Metadaten reserviert.

* Die Node-Ressourcen, die nur auf Softwarebasierten Metadaten basieren, müssen mit den vorhandenen Storage-Nodes-Ressourcen übereinstimmen. Beispiel:
+
** Wenn der bestehende StorageGRID Standort SG6000 oder SG6100 Appliances verwendet, müssen die rein softwarebasierten Nodes mit Metadaten die folgenden Mindestanforderungen erfüllen:
+
*** 128 GB RAM
*** 8-Core-CPU
*** 8 TB SSD oder äquivalenter Storage für die Cassandra-Datenbank (rangedb/0)


** Wenn die vorhandene StorageGRID Site virtuelle Speicherknoten mit 24 GB RAM, 8-Kern-CPU und 3 TB oder 4 TB Metadatenspeicher verwendet, sollten die softwarebasierten Nur-Metadaten-Knoten ähnliche Ressourcen verwenden (24 GB RAM, 8-Kern-CPU und 4 TB Metadatenspeicher (rangedb/0)).
+
Beim Hinzufügen eines neuen StorageGRID Standorts sollte die Metadaten-Gesamtkapazität des neuen Standorts mindestens den vorhandenen StorageGRID Standorten entsprechen, und neue Standortressourcen sollten den Storage-Nodes an den vorhandenen StorageGRID Standorten entsprechen.



* Wenn Sie ein neues System installieren (StorageGRID 11.6 oder höher) und jeder Speicherknoten mindestens 128 GB RAM hat, weisen Sie Volume 0 mindestens 8 TB zu. Bei Verwendung eines größeren Werts für Volume 0 kann der zulässige Speicherplatz für Metadaten auf jedem Storage Node erhöht werden.
* Verwenden Sie bei der Konfiguration verschiedener Storage-Nodes für einen Standort, falls möglich, die gleiche Einstellung für Volume 0. Wenn ein Standort Storage-Nodes unterschiedlicher Größe enthält, bestimmt der Storage-Node mit dem kleinsten Volume 0 die Metadaten-Kapazität dieses Standorts.


Weitere Informationen finden Sie unter link:../admin/managing-object-metadata-storage.html["Management von Objekt-Metadaten-Storage"].
