---
permalink: maintain/decommissioning-disconnected-grid-nodes.html 
sidebar: sidebar 
keywords: storagegrid, disconnected nodes, decommission node 
summary: 'Möglicherweise müssen Sie einen Knoten außer Betrieb setzen, der derzeit nicht mit dem Grid \(One verbunden ist, dessen Status unbekannt oder administrativ ausgefallen ist\).' 
---
= Die getrennten Grid-Nodes werden deaktiviert
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Möglicherweise müssen Sie einen Knoten außer Betrieb setzen, der derzeit nicht mit dem Grid verbunden ist (einen Node, dessen Status unbekannt oder administrativ ausgefallen ist).

.Bevor Sie beginnen
* Sie verstehen die Überlegungen zur Stilllegung link:considerations-for-decommissioning-admin-or-gateway-nodes.html["Admin- und Gateway-Nodes"] und die Überlegungen zur Stilllegung link:considerations-for-decommissioning-storage-nodes.html["Storage-Nodes"].
* Sie haben alle erforderlichen Elemente erhalten.
* Sie haben sichergestellt, dass keine Datenreparaturjobs aktiv sind. Siehe link:checking-data-repair-jobs.html["Prüfen Sie die Reparatur von Daten"].
* Sie haben bestätigt, dass die Wiederherstellung von Storage-Nodes an keiner Stelle im Grid ausgeführt wird. In diesem Fall müssen Sie warten, bis alle Cassandra-Rebuilds im Rahmen der Recovery abgeschlossen sind. Anschließend können Sie mit der Stilllegung fortfahren.
* Sie haben sichergestellt, dass andere Wartungsvorgänge während der Deaktivierung des Nodes nicht ausgeführt werden, es sei denn, der Vorgang zur Deaktivierung des Nodes wurde angehalten.
* Die Spalte *Decommission möglich* für den Knoten oder Knoten, die Sie außer Betrieb nehmen möchten, enthält ein grünes Häkchen.
* Sie haben die Provisionierungs-Passphrase.


.Über diese Aufgabe
Sie können getrennte Knoten identifizieren, indem Sie in der Spalte *Health* nach dem blauen Symbol Unbekannt oder dem grauen Symbol administrativ unten image:../media/icon_alarm_gray_administratively_down.png["Symbol administrativ nicht verfügbar"]suchenimage:../media/icon_alarm_blue_unknown.png["Symbol Unbekannt"].

Beachten Sie vor dem Stilllegen getrennter Nodes Folgendes:

* Dieses Verfahren dient in erster Linie zum Entfernen eines einzelnen nicht verbundenen Knotens. Wenn Ihr Grid mehrere getrennte Knoten enthält, muss die Software gleichzeitig ausmustern, wodurch das Potenzial für unerwartete Ergebnisse erhöht wird.
+

CAUTION: Es kann zu Datenverlusten kommen, wenn Sie mehr als einen getrennten Storage Node gleichzeitig stilllegen. Siehe link:considerations-for-decommissioning-storage-nodes.html#considerations-disconnected-storage-nodes["Überlegungen zu getrennten Storage-Nodes"].

+

CAUTION: Gehen Sie mit Vorsicht vor, wenn Sie Storage-Nodes in einem Grid stilllegen, das rein softwarebasierte Metadaten-Nodes enthält. Wenn Sie alle Knoten außer Betrieb nehmen, die für den Speicher _sowohl_ Objekte als auch Metadaten konfiguriert sind, wird die Fähigkeit zum Speichern von Objekten aus dem Raster entfernt. Weitere Informationen zu nur Metadaten-Storage-Nodes finden Sie unterlink:../primer/what-storage-node-is.html#types-of-storage-nodes["Typen von Storage-Nodes"].

* Wenn ein getrennter Knoten nicht entfernt werden kann (z. B. ein Speicher-Knoten, der für das ADC-Quorum erforderlich ist), kann kein anderer getrennter Knoten entfernt werden.


.Schritte
. Versuchen Sie, alle nicht verbundenen Grid-Nodes wieder online zu schalten oder wiederherzustellen, sofern Sie einen Archive Node nicht stilllegen (der getrennt werden muss).
+
Anweisungen finden Sie unter link:warnings-and-considerations-for-grid-node-recovery.html["Verfahren zur Recovery von Grid-Nodes"] .

. Wenn Sie einen nicht verbundenen Grid-Node nicht wiederherstellen können und ihn während der Trennung außer Betrieb nehmen möchten, aktivieren Sie das Kontrollkästchen für diesen Node.
+

NOTE: Wenn Ihr Grid mehrere getrennte Knoten enthält, muss die Software gleichzeitig ausmustern, wodurch das Potenzial für unerwartete Ergebnisse erhöht wird.

+

CAUTION: Seien Sie vorsichtig, wenn Sie mehrere getrennte Grid-Nodes gleichzeitig stilllegen möchten, insbesondere wenn Sie mehrere getrennte Storage-Nodes auswählen. Wenn Sie mehr als einen getrennten Storage Node haben, den Sie nicht wiederherstellen können, wenden Sie sich an den technischen Support, um die beste Vorgehensweise zu ermitteln.

. Geben Sie die Provisionierungs-Passphrase ein.
+
Die Schaltfläche *Start Decommission* ist aktiviert.

. Klicken Sie Auf *Start Decommission*.
+
Es wird eine Warnung angezeigt, die angibt, dass Sie einen nicht verbundenen Knoten ausgewählt haben und dass Objektdaten verloren gehen, wenn der Knoten die einzige Kopie eines Objekts hat.

. Überprüfen Sie die Liste der Knoten, und klicken Sie auf *OK*.
+
Der Vorgang zur Deaktivierung wird gestartet und für jeden Node wird der Fortschritt angezeigt. Während des Verfahrens wird ein neues Wiederherstellungspaket erstellt, das die Änderung der Grid-Konfiguration enthält.

. Sobald das neue Wiederherstellungspaket verfügbar ist, klicken Sie auf den Link oder wählen Sie *WARTUNG* > *System* > *Wiederherstellungspaket*, um auf die Seite des Wiederherstellungspakets zuzugreifen. Laden Sie dann die Datei herunter `.zip`.
+
Siehe die Anleitung für link:downloading-recovery-package.html["Das Wiederherstellungspaket wird heruntergeladen"].

+

NOTE: Laden Sie das Wiederherstellungspaket so schnell wie möglich herunter, um sicherzustellen, dass Sie Ihr Grid wiederherstellen können, wenn während des Stilllegungsvorgangs etwas schief geht.

+

CAUTION: Die Wiederherstellungspaket-Datei muss gesichert werden, da sie Verschlüsselungsschlüssel und Passwörter enthält, die verwendet werden können, um Daten vom StorageGRID-System zu erhalten.

. Überwachen Sie die Seite Dekommission regelmäßig, um sicherzustellen, dass alle ausgewählten Knoten erfolgreich außer Betrieb gesetzt werden.
+
Storage-Nodes können Tage oder Wochen ausmustern. Wenn alle Aufgaben abgeschlossen sind, wird die Liste der Knotenauswahl mit einer Erfolgsmeldung erneut angezeigt. Wenn Sie einen getrennten Speicherknoten außer Betrieb genommen haben, zeigt eine Informationsmeldung an, dass die Reparaturaufträge gestartet wurden.

. Nachdem die Nodes im Rahmen der Stilllegung automatisch heruntergefahren wurden, entfernen Sie alle verbleibenden Virtual Machines oder anderen Ressourcen, die dem ausgemusterten Node zugeordnet sind.
+

CAUTION: Führen Sie diesen Schritt erst aus, wenn die Nodes automatisch heruntergefahren wurden.

. Wenn Sie einen Storage Node außer Betrieb nehmen, überwachen Sie den Status der Reparatur-Jobs mit *replizierten Daten* und *Erasure-codierten (EC) Daten*, die während des Stilllegungsprozesses automatisch gestartet werden.


[role="tabbed-block"]
====
.Replizierte Daten
--
* Um einen geschätzten Fertigstellungsgrad für die replizierte Reparatur zu erhalten, fügen Sie die Option zum Befehl Repair-Data hinzu `show-replicated-repair-status`.
+
`repair-data show-replicated-repair-status`

* So stellen Sie fest, ob Reparaturen abgeschlossen sind:
+
.. Wählen Sie *NODES* > *_Storage Node wird repariert_* > *ILM*.
.. Prüfen Sie die Attribute im Abschnitt Bewertung. Wenn die Reparaturen abgeschlossen sind, weist das Attribut *wartet - Alle* 0 Objekte an.


* So überwachen Sie die Reparatur genauer:
+
.. Wählen Sie *KNOTEN*.
.. Wählen Sie *_Grid Name_* > *ILM* aus.
.. Setzen Sie den Mauszeiger über das ILM-Warteschlangendiagramm, um den Wert des Attributs *Scan Rate (Objects/sec)* anzuzeigen. Dies ist die Rate, mit der Objekte im Raster gescannt und für ILM in die Warteschlange eingereiht werden.
.. Sehen Sie sich im Abschnitt ILM-Warteschlange die folgenden Attribute an:
+
*** *Scan-Zeitraum - geschätzt*: Die geschätzte Zeit, um einen vollständigen ILM-Scan aller Objekte durchzuführen.
+
Ein vollständiger Scan kann nicht garantieren, dass ILM auf alle Objekte angewendet wurde.

*** *Reparaturversuche*: Die Gesamtzahl der Objektreparaturoperationen für replizierte Daten, die versucht wurden. Diese Zählung erhöht sich jedes Mal, wenn ein Storage-Node versucht, ein Objekt mit hohem Risiko zu reparieren. Risikobehaftete ILM-Reparaturen werden priorisiert, wenn das Grid besetzt wird.
+
Die Reparatur desselben Objekts erhöht sich möglicherweise erneut, wenn die Replikation nach der Reparatur fehlgeschlagen ist. + Diese Attribute können nützlich sein, wenn Sie den Fortschritt der Storage Node Volume Recovery überwachen. Wenn die Anzahl der versuchten Reparaturen nicht mehr steigt und ein vollständiger Scan abgeschlossen wurde, ist die Reparatur wahrscheinlich abgeschlossen.



.. Alternativ können Sie auch eine Prometheus-Abfrage für und `storagegrid_ilm_repairs_attempted` einreichen `storagegrid_ilm_scan_period_estimated_minutes`.




--
.EC-Daten (Erasure Coded)
--
So überwachen Sie die Reparatur von Daten mit Verfahren zur Einhaltung von Datenkonsistenz und versuchen Sie es erneut, eventuell fehlgeschlagene Anfragen zu senden:

. Status von Datenreparaturen mit Löschungscode ermitteln:
+
** Wählen Sie *SUPPORT* > *Tools* > *Metrics*, um die geschätzte Zeit bis zum Abschluss und den Fertigstellungsgrad für den aktuellen Job anzuzeigen. Wählen Sie dann im Abschnitt Grafana die Option *EC Übersicht* aus. Sehen Sie sich die Dashboards *Grid EC Job Estimated Time to Completion* und *Grid EC Job prozentual Completed* an.
** Mit diesem Befehl können Sie den Status einer bestimmten Operation anzeigen `repair-data`:
+
`repair-data show-ec-repair-status --repair-id repair ID`

** Verwenden Sie diesen Befehl, um alle Reparaturen aufzulisten:
+
`repair-data show-ec-repair-status`

+
Die Ausgabe listet Informationen auf, einschließlich `repair ID`, für alle zuvor ausgeführten und aktuell laufenden Reparaturen.



. Wenn die Ausgabe zeigt, dass der Reparaturvorgang fehlgeschlagen ist, verwenden Sie `--repair-id` die Option, um die Reparatur erneut zu versuchen.
+
Mit diesem Befehl wird eine fehlerhafte Node-Reparatur mithilfe der Reparatur-ID 6949309319275667690 erneut versucht:

+
`repair-data start-ec-node-repair --repair-id 6949309319275667690`

+
Mit diesem Befehl wird eine fehlerhafte Volume-Reparatur mithilfe der Reparatur-ID 6949309319275667690 wiederholt:

+
`repair-data start-ec-volume-repair --repair-id 6949309319275667690`



--
====
.Nachdem Sie fertig sind
Sobald die getrennten Nodes außer Betrieb genommen und alle Reparatur-Jobs abgeschlossen sind, können Sie alle verbundenen Grid-Nodes je nach Bedarf ausmustern.

Führen Sie anschließend die folgenden Schritte aus, nachdem Sie den Vorgang zur Deaktivierung abgeschlossen haben:

* Stellen Sie sicher, dass die Laufwerke des ausgemusterten Grid-Node sauber gelöscht werden. Verwenden Sie ein handelsübliches Datenwischwerkzeug oder einen Dienst, um die Daten dauerhaft und sicher von den Laufwerken zu entfernen.
* Wenn Sie einen Appliance-Node deaktiviert haben und die Daten auf der Appliance mithilfe der Node-Verschlüsselung geschützt wurden, löschen Sie die Konfiguration des Verschlüsselungsmanagement-Servers (Clear KMS) mithilfe des StorageGRID Appliance Installer. Wenn Sie die Appliance einem anderen Grid hinzufügen möchten, müssen Sie die KMS-Konfiguration löschen. Anweisungen hierzu finden Sie unter https://docs.netapp.com/us-en/storagegrid-appliances/commonhardware/monitoring-node-encryption-in-maintenance-mode.html["Überwachung der Node-Verschlüsselung im Wartungsmodus"^].

